{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "\n",
    "# fetch dataset \n",
    "spambase = fetch_ucirepo(id=94) \n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = spambase.data.features \n",
    "y = spambase.data.targets \n",
    "\n",
    "data = pd.concat([X, y], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ten fold cv\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# stratified ten-fold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# lst to store metrics\n",
    "rf_accuracy_scores = []\n",
    "rf_f1_scores = []\n",
    "rf_training_times = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx].squeeze(), y.iloc[test_idx].squeeze() #squeeze() to ensure 1D array\n",
    "\n",
    "    # training time\n",
    "    start_time = time.time()\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_training_times.append(time.time() - start_time)\n",
    "\n",
    "    # make prediction on test data\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "\n",
    "    # compute metrics\n",
    "    rf_accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    rf_f1_scores.append(f1_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# lists to store measures\n",
    "nb_accuracy_scores = []\n",
    "nb_f1_scores = []\n",
    "nb_training_times = []\n",
    "\n",
    "# cross validation\n",
    "\n",
    "for train_idx, test_idx in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx].squeeze(), y.iloc[test_idx].squeeze()\n",
    "\n",
    "    start_time = time.time()\n",
    "    nb_model.fit(X_train, y_train)\n",
    "\n",
    "    nb_training_times.append(time.time() - start_time)\n",
    "\n",
    "    y_pred = nb_model.predict(X_test)\n",
    "\n",
    "    nb_accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    nb_f1_scores.append(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC()\n",
    "svm_accuracy_scores = []\n",
    "svm_f1_scores = []\n",
    "svm_training_times = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index].squeeze(), y.iloc[test_index].squeeze()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    svm.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    y_pred = svm.predict(X_test)\n",
    "    svm_accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    svm_f1_scores.append(f1_score(y_test, y_pred))\n",
    "    svm_training_times.append(training_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Times:\n",
      " Fold  Random Forest  Naive Bayes  Support Vector Machines\n",
      "    1         0.3899       0.0023                   0.2445\n",
      "    2         0.3842       0.0018                   0.2588\n",
      "    3         0.3835       0.0018                   0.2466\n",
      "    4         0.3800       0.0021                   0.2406\n",
      "    5         0.3801       0.0019                   0.2426\n",
      "    6         0.3755       0.0018                   0.2562\n",
      "    7         0.3767       0.0019                   0.2476\n",
      "    8         0.3770       0.0018                   0.2489\n",
      "    9         0.3850       0.0021                   0.2492\n",
      "   10         0.3771       0.0020                   0.2393\n",
      "  avg         0.3809       0.0019                   0.2474\n",
      "stdev         0.0044       0.0002                   0.0060\n"
     ]
    }
   ],
   "source": [
    "# Step 2\n",
    "\n",
    "# 2.1 training time\n",
    "\n",
    "print(\"\\nTraining Times:\")\n",
    "\n",
    "results_training_time = pd.DataFrame({\n",
    "    \"Fold\": [i+1 for i in range(10)],\n",
    "    \"Random Forest\": rf_training_times,\n",
    "    \"Naive Bayes\": nb_training_times,\n",
    "    \"Support Vector Machines\": svm_training_times\n",
    "})\n",
    "\n",
    "results_training_time = pd.concat([\n",
    "    results_training_time,\n",
    "    pd.DataFrame({\n",
    "        \"Fold\": [\"avg\", \"stdev\"], \n",
    "        \"Random Forest\": [np.mean(rf_training_times), np.std(rf_training_times)],\n",
    "        \"Naive Bayes\": [np.mean(nb_training_times), np.std(nb_training_times)],\n",
    "        \"Support Vector Machines\": [np.mean(svm_training_times), np.std(svm_training_times)]\n",
    "    })\n",
    "], ignore_index=True)\n",
    "\n",
    "print(results_training_time.to_string(index=False, float_format=\"%.4f\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:\n",
      " Fold  Random Forest  Naive Bayes  Support Vector Machines\n",
      "    1         0.9523       0.8243                   0.7158\n",
      "    2         0.9565       0.8196                   0.7196\n",
      "    3         0.9609       0.8043                   0.7348\n",
      "    4         0.9674       0.8217                   0.7109\n",
      "    5         0.9457       0.8174                   0.7196\n",
      "    6         0.9587       0.7891                   0.7391\n",
      "    7         0.9565       0.8457                   0.6935\n",
      "    8         0.9565       0.8261                   0.7065\n",
      "    9         0.9435       0.8413                   0.7022\n",
      "   10         0.9522       0.8130                   0.7065\n",
      "  avg         0.9550       0.8203                   0.7148\n",
      "stdev         0.0067       0.0156                   0.0134\n"
     ]
    }
   ],
   "source": [
    "# 2.2 accuracy\n",
    "\n",
    "print(\"\\nAccuracy:\")\n",
    "\n",
    "results_accuracy = pd.DataFrame({\n",
    "    \"Fold\": [i+1 for i in range(10)],\n",
    "    \"Random Forest\": rf_accuracy_scores,\n",
    "    \"Naive Bayes\": nb_accuracy_scores,\n",
    "    \"Support Vector Machines\": svm_accuracy_scores\n",
    "})\n",
    "\n",
    "results_accuracy = pd.concat([\n",
    "    results_accuracy,\n",
    "    pd.DataFrame({\n",
    "        \"Fold\": [\"avg\", \"stdev\"], \n",
    "        \"Random Forest\": [np.mean(rf_accuracy_scores), np.std(rf_accuracy_scores)],\n",
    "        \"Naive Bayes\": [np.mean(nb_accuracy_scores), np.std(nb_accuracy_scores)],\n",
    "        \"Support Vector Machines\": [np.mean(svm_accuracy_scores), np.std(svm_accuracy_scores)]\n",
    "    })\n",
    "], ignore_index=True)\n",
    "\n",
    "print(results_accuracy.to_string(index=False, float_format=\"%.4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F-score:\n",
      " Fold  Random Forest  Naive Bayes  Support Vector Machines\n",
      "    1         0.9389       0.8103                   0.5529\n",
      "    2         0.9441       0.8074                   0.5597\n",
      "    3         0.9500       0.7945                   0.5612\n",
      "    4         0.9580       0.8102                   0.5723\n",
      "    5         0.9311       0.8065                   0.5657\n",
      "    6         0.9471       0.7810                   0.5652\n",
      "    7         0.9448       0.8297                   0.5466\n",
      "    8         0.9438       0.8095                   0.5659\n",
      "    9         0.9266       0.8274                   0.5387\n",
      "   10         0.9375       0.8018                   0.5455\n",
      "  avg         0.9422       0.8078                   0.5574\n",
      "stdev         0.0086       0.0135                   0.0104\n"
     ]
    }
   ],
   "source": [
    "# 2.3 F-measure\n",
    "\n",
    "print(\"\\nF-score:\")\n",
    "\n",
    "results_fscore = pd.DataFrame({\n",
    "    \"Fold\": [i+1 for i in range(10)],\n",
    "    \"Random Forest\": rf_f1_scores,\n",
    "    \"Naive Bayes\": nb_f1_scores,\n",
    "    \"Support Vector Machines\": svm_f1_scores\n",
    "})\n",
    "\n",
    "results_fscore = pd.concat([\n",
    "    results_fscore,\n",
    "    pd.DataFrame({\n",
    "        \"Fold\": [\"avg\", \"stdev\"], \n",
    "        \"Random Forest\": [np.mean(rf_f1_scores), np.std(rf_f1_scores)],\n",
    "        \"Naive Bayes\": [np.mean(nb_f1_scores), np.std(nb_f1_scores)],\n",
    "        \"Support Vector Machines\": [np.mean(svm_f1_scores), np.std(svm_f1_scores)]\n",
    "    })\n",
    "], ignore_index=True)\n",
    "\n",
    "print(results_fscore.to_string(index=False, float_format=\"%.4f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Times:\n",
      "    Fold Random Forest Naive Bayes Support Vector Machines\n",
      "       1    0.3899 (3)  0.0023 (1)              0.2445 (2)\n",
      "       2    0.3842 (3)  0.0018 (1)              0.2588 (2)\n",
      "       3    0.3835 (3)  0.0018 (1)              0.2466 (2)\n",
      "       4    0.3800 (3)  0.0021 (1)              0.2406 (2)\n",
      "       5    0.3801 (3)  0.0019 (1)              0.2426 (2)\n",
      "       6    0.3755 (3)  0.0018 (1)              0.2562 (2)\n",
      "       7    0.3767 (3)  0.0019 (1)              0.2476 (2)\n",
      "       8    0.3770 (3)  0.0018 (1)              0.2489 (2)\n",
      "       9    0.3850 (3)  0.0021 (1)              0.2492 (2)\n",
      "      10    0.3771 (3)  0.0020 (1)              0.2393 (2)\n",
      "avg rank          3.00        1.00                    2.00\n"
     ]
    }
   ],
   "source": [
    "# remove avg and stdev from the measures\n",
    "results_training_time_no_avg_stdev = results_training_time.iloc[:-2, :]\n",
    "\n",
    "# rank the measures\n",
    "ranks_training_time = results_training_time_no_avg_stdev.iloc[:, 1:].rank(axis=1, ascending=True, method='min')\n",
    "\n",
    "# add ranks to the measures\n",
    "results_training_time_with_ranks = results_training_time_no_avg_stdev.copy()\n",
    "for col in [\"Random Forest\", \"Naive Bayes\", \"Support Vector Machines\"]:\n",
    "    results_training_time_with_ranks[col] = results_training_time_with_ranks[col].apply(lambda x: f\"{x:.4f}\") + \" (\" + ranks_training_time[col].astype(int).astype(str) + \")\"\n",
    "\n",
    "# calculate avg ranks\n",
    "average_ranks_training_time = ranks_training_time.mean().round(2)\n",
    "\n",
    "# create dataframe with avg ranks\n",
    "average_ranks_training_time_row = pd.DataFrame({\n",
    "    \"Fold\": [\"avg rank\"],\n",
    "    \"Random Forest\": [f\"{average_ranks_training_time['Random Forest']:.2f}\"],\n",
    "    \"Naive Bayes\": [f\"{average_ranks_training_time['Naive Bayes']:.2f}\"],\n",
    "    \"Support Vector Machines\": [f\"{average_ranks_training_time['Support Vector Machines']:.2f}\"]\n",
    "})\n",
    "\n",
    "# append the avg rank row to the results for each metric\n",
    "results_training_time_with_ranks = pd.concat([results_training_time_with_ranks, average_ranks_training_time_row], ignore_index=True)\n",
    "\n",
    "print(\"\\nTraining Times:\")\n",
    "print(results_training_time_with_ranks.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy with:\n",
      "    Fold Random Forest Naive Bayes Support Vector Machines\n",
      "       1    0.9523 (1)  0.8243 (2)              0.7158 (3)\n",
      "       2    0.9565 (1)  0.8196 (2)              0.7196 (3)\n",
      "       3    0.9609 (1)  0.8043 (2)              0.7348 (3)\n",
      "       4    0.9674 (1)  0.8217 (2)              0.7109 (3)\n",
      "       5    0.9457 (1)  0.8174 (2)              0.7196 (3)\n",
      "       6    0.9587 (1)  0.7891 (2)              0.7391 (3)\n",
      "       7    0.9565 (1)  0.8457 (2)              0.6935 (3)\n",
      "       8    0.9565 (1)  0.8261 (2)              0.7065 (3)\n",
      "       9    0.9435 (1)  0.8413 (2)              0.7022 (3)\n",
      "      10    0.9522 (1)  0.8130 (2)              0.7065 (3)\n",
      "avg rank          1.00        2.00                    3.00\n"
     ]
    }
   ],
   "source": [
    "# remove avg and stdev from the measures\n",
    "results_accuracy_no_avg_stdev = results_accuracy.iloc[:-2, :]\n",
    "\n",
    "# rank the measures\n",
    "ranks_accuracy = results_accuracy_no_avg_stdev.iloc[:, 1:].rank(axis=1, ascending=False, method='min')\n",
    "\n",
    "# add ranks to the measures\n",
    "results_accuracy_with_ranks = results_accuracy_no_avg_stdev.copy()\n",
    "for col in [\"Random Forest\", \"Naive Bayes\", \"Support Vector Machines\"]:\n",
    "    results_accuracy_with_ranks[col] = results_accuracy_with_ranks[col].apply(lambda x: f\"{x:.4f}\") + \" (\" + ranks_accuracy[col].astype(int).astype(str) + \")\"\n",
    "\n",
    "# calculate avg ranks\n",
    "average_ranks_accuracy = ranks_accuracy.mean().round(2)\n",
    "\n",
    "# create dataframe with avg ranks\n",
    "average_ranks_accuracy_row = pd.DataFrame({\n",
    "    \"Fold\": [\"avg rank\"],\n",
    "    \"Random Forest\": [f\"{average_ranks_accuracy['Random Forest']:.2f}\"],\n",
    "    \"Naive Bayes\": [f\"{average_ranks_accuracy['Naive Bayes']:.2f}\"],\n",
    "    \"Support Vector Machines\": [f\"{average_ranks_accuracy['Support Vector Machines']:.2f}\"]\n",
    "})\n",
    "\n",
    "# append the avg rank row to the results for each metric\n",
    "results_accuracy_with_ranks = pd.concat([results_accuracy_with_ranks, average_ranks_accuracy_row], ignore_index=True)\n",
    "\n",
    "print(\"\\nAccuracy with:\")\n",
    "print(results_accuracy_with_ranks.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1-Score:\n",
      "    Fold Random Forest Naive Bayes Support Vector Machines\n",
      "       1    0.9389 (1)  0.8103 (2)              0.5529 (3)\n",
      "       2    0.9441 (1)  0.8074 (2)              0.5597 (3)\n",
      "       3    0.9500 (1)  0.7945 (2)              0.5612 (3)\n",
      "       4    0.9580 (1)  0.8102 (2)              0.5723 (3)\n",
      "       5    0.9311 (1)  0.8065 (2)              0.5657 (3)\n",
      "       6    0.9471 (1)  0.7810 (2)              0.5652 (3)\n",
      "       7    0.9448 (1)  0.8297 (2)              0.5466 (3)\n",
      "       8    0.9438 (1)  0.8095 (2)              0.5659 (3)\n",
      "       9    0.9266 (1)  0.8274 (2)              0.5387 (3)\n",
      "      10    0.9375 (1)  0.8018 (2)              0.5455 (3)\n",
      "avg rank          1.00        2.00                    3.00\n"
     ]
    }
   ],
   "source": [
    "# remove avg and stdev from the measures\n",
    "results_fscore_no_avg_stdev = results_fscore.iloc[:-2, :]\n",
    "\n",
    "# rank the measures\n",
    "ranks_fscore = results_fscore_no_avg_stdev.iloc[:, 1:].rank(axis=1, ascending=False, method='min')\n",
    "\n",
    "# add ranks to the measures\n",
    "results_fscore_with_ranks = results_fscore_no_avg_stdev.copy()\n",
    "for col in [\"Random Forest\", \"Naive Bayes\", \"Support Vector Machines\"]:\n",
    "    results_fscore_with_ranks[col] = results_fscore_with_ranks[col].apply(lambda x: f\"{x:.4f}\") + \" (\" + ranks_fscore[col].astype(int).astype(str) + \")\"\n",
    "\n",
    "# calculate avg ranks\n",
    "average_ranks_fscore = ranks_fscore.mean().round(2)\n",
    "\n",
    "average_ranks_fscore_row = pd.DataFrame({\n",
    "    \"Fold\": [\"avg rank\"],\n",
    "    \"Random Forest\": [f\"{average_ranks_fscore['Random Forest']:.2f}\"],\n",
    "    \"Naive Bayes\": [f\"{average_ranks_fscore['Naive Bayes']:.2f}\"],\n",
    "    \"Support Vector Machines\": [f\"{average_ranks_fscore['Support Vector Machines']:.2f}\"]\n",
    "})\n",
    "\n",
    "# append the avg rank row to the results for each metric\n",
    "results_fscore_with_ranks = pd.concat([results_fscore_with_ranks, average_ranks_fscore_row], ignore_index=True)\n",
    "\n",
    "print(\"\\nF1-Score:\")\n",
    "print(results_fscore_with_ranks.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Time:\n",
      "Friedman Statistic: 20.0\n",
      "Training Time Critical Value: 5.9915\n",
      "There are significant differences between algorithms (20.0000 > 5.9915)\n",
      "\n",
      "Nemenyi test\n",
      "Critical difference: 1.0478214542564015\n",
      "Significant difference between Random Forest and Naive Bayes (abs difference: 2.0)\n",
      "No significant difference between Random Forest and Support Vector Machines (abs difference: 1.0)\n",
      "No significant difference between Naive Bayes and Support Vector Machines (abs difference: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dp/msy6kbpd5_x1d53g8f_x_0zh0000gn/T/ipykernel_1401/618587486.py:52: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  difference = abs(average_ranks[i] - average_ranks[j])\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "# step 3 friedman test\n",
    "\n",
    "def friedman_test(average_ranks, ranks, n, k):\n",
    "\n",
    "    print()\n",
    "    # calculate average rank\n",
    "    avg_rank = (k + 1) / 2\n",
    "\n",
    "    # calculate sum of squared differences\n",
    "    nominator = 0\n",
    "    for rank in average_ranks:\n",
    "        nominator += (rank - avg_rank)**2\n",
    "    nominator *= n\n",
    "\n",
    "    denominator = 0\n",
    "    for rank in ranks.values.flatten():\n",
    "        denominator += (rank - avg_rank) ** 2\n",
    "\n",
    "    denominator *= (1 / (n * (k - 1)))\n",
    "\n",
    "    friedman_statistic = nominator / denominator\n",
    "\n",
    "    df = k - 1 # degrees of freedom\n",
    "    alpha = 0.05\n",
    "    critical_value = chi2.ppf(1 - alpha, df)\n",
    "\n",
    "    return friedman_statistic, critical_value\n",
    "\n",
    "training_time_friedman_statistic, training_time_critical_value = friedman_test(\n",
    "                                                        average_ranks=average_ranks_training_time, \n",
    "                                                        ranks=ranks_training_time, n=10, k=3)\n",
    "\n",
    "print(\"Training Time:\")\n",
    "print(f\"Friedman Statistic: {training_time_friedman_statistic}\")\n",
    "\n",
    "\n",
    "print(f\"Training Time Critical Value: {training_time_critical_value:.4f}\")\n",
    "\n",
    "if training_time_friedman_statistic > training_time_critical_value:\n",
    "    print(f\"There are significant differences between algorithms ({training_time_friedman_statistic:.4f} > {training_time_critical_value:.4f})\")\n",
    "else:\n",
    "    print(f\"There are no significant differences between algorithms ({training_time_friedman_statistic:.4f} < {training_time_critical_value:.4f})\")\n",
    "\n",
    "# step 4 nemenyi test\n",
    "\n",
    "def nemenyi_test(q_alpha, k, n, average_ranks, algorithms):\n",
    "    \n",
    "    critical_difference = q_alpha * np.sqrt((k * (k + 1)) / (6 * n))\n",
    "    print(f\"Critical difference: {critical_difference}\")\n",
    "    \n",
    "    for i in range(k):\n",
    "        for j in range(i + 1, k):\n",
    "            # difference between average ranks\n",
    "            difference = abs(average_ranks[i] - average_ranks[j])\n",
    "            \n",
    "            # significance\n",
    "            if difference > critical_difference:\n",
    "                print(f\"Significant difference between {algorithms[i]} and {algorithms[j]} (abs difference: {difference})\")\n",
    "            else:\n",
    "                print(f\"No significant difference between {algorithms[i]} and {algorithms[j]} (abs difference: {difference})\")\n",
    "    \n",
    "print(\"\\nNemenyi test\")\n",
    "nemenyi_test(q_alpha=2.343, k=3, n=10, \n",
    "             average_ranks=average_ranks_training_time,\n",
    "             algorithms=[\"Random Forest\", \"Naive Bayes\", \"Support Vector Machines\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:\n",
      "Friedman Statistic: 20.0\n",
      "Training Time Critical Value: 5.9915\n",
      "There are significant differences between algorithms (20.0000 > 5.9915)\n",
      "Critical difference: 1.0478214542564015\n",
      "No significant difference between Random Forest and Naive Bayes (abs difference: 1.0)\n",
      "Significant difference between Random Forest and Support Vector Machines (abs difference: 2.0)\n",
      "No significant difference between Naive Bayes and Support Vector Machines (abs difference: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dp/msy6kbpd5_x1d53g8f_x_0zh0000gn/T/ipykernel_1401/618587486.py:52: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  difference = abs(average_ranks[i] - average_ranks[j])\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy_friedman_statistic, accuracy_critical_value = friedman_test(\n",
    "                                                        average_ranks=average_ranks_accuracy, \n",
    "                                                        ranks=ranks_accuracy, n=10, k=3)\n",
    "print(\"Accuracy:\")\n",
    "print(f\"Friedman Statistic: {accuracy_friedman_statistic}\")\n",
    "\n",
    "\n",
    "print(f\"Training Time Critical Value: {accuracy_critical_value:.4f}\")\n",
    "\n",
    "if accuracy_friedman_statistic > accuracy_critical_value:\n",
    "    print(f\"There are significant differences between algorithms ({accuracy_friedman_statistic:.4f} > {accuracy_critical_value:.4f})\")\n",
    "else:\n",
    "    print(f\"There are no significant differences between algorithms ({accuracy_friedman_statistic:.4f} < {accuracy_critical_value:.4f})\")\n",
    "\n",
    "nemenyi_test(q_alpha=2.343, k=3, n=10, \n",
    "             average_ranks=average_ranks_accuracy,\n",
    "             algorithms=[\"Random Forest\", \"Naive Bayes\", \"Support Vector Machines\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1 score:\n",
      "Friedman Statistic: 20.0\n",
      "Training Time Critical Value: 5.9915\n",
      "There are significant differences between algorithms (20.0000 > 5.9915)\n",
      "Critical difference: 1.0478214542564015\n",
      "No significant difference between Random Forest and Naive Bayes (abs difference: 1.0)\n",
      "Significant difference between Random Forest and Support Vector Machines (abs difference: 2.0)\n",
      "No significant difference between Naive Bayes and Support Vector Machines (abs difference: 1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dp/msy6kbpd5_x1d53g8f_x_0zh0000gn/T/ipykernel_1401/618587486.py:52: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  difference = abs(average_ranks[i] - average_ranks[j])\n"
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "fscore_friedman_statistic, fscore_critical_value = friedman_test(\n",
    "                                                        average_ranks=average_ranks_fscore, \n",
    "                                                        ranks=ranks_fscore, n=10, k=3)\n",
    "print(\"F1 score:\")\n",
    "print(f\"Friedman Statistic: {fscore_friedman_statistic}\")\n",
    "\n",
    "print(f\"Training Time Critical Value: {fscore_critical_value:.4f}\")\n",
    "\n",
    "if fscore_friedman_statistic > accuracy_critical_value:\n",
    "    print(f\"There are significant differences between algorithms ({fscore_friedman_statistic:.4f} > {fscore_critical_value:.4f})\")\n",
    "else:\n",
    "    print(f\"There are no significant differences between algorithms ({fscore_friedman_statistic:.4f} < {fscore_critical_value:.4f})\")\n",
    "\n",
    "nemenyi_test(q_alpha=2.343, k=3, n=10, \n",
    "             average_ranks=average_ranks_fscore,\n",
    "             algorithms=[\"Random Forest\", \"Naive Bayes\", \"Support Vector Machines\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
